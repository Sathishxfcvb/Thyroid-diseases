# -*- coding: utf-8 -*-
"""Throid.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XdyF4WQKplQO2h5rsc49PJqxCTVLYgvq
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()

from sklearn import preprocessing

from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier

from sklearn.feature_selection import f_regression
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.model_selection import RandomizedSearchCV, GridSearchCV
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import precision_score, recall_score, f1_score

import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv("drug200.csv")
df.head()

df['Drug'].unique()

df['Cholesterol'].unique()
df["BP"].unique()
df['Sex'].unique()

le1 = preprocessing.LabelEncoder()
df['Drug']= le1.fit_transform(df['Drug'])
df['Cholesterol']= le1.fit_transform(df['Cholesterol'])
df['BP']= le1.fit_transform(df['BP'])
df['Sex']= le1.fit_transform(df['Sex'])

len(df)
df["Drug"].value_counts().plot(kind="bar");
df["Cholesterol"].value_counts().plot(kind="bar");
df["Sex"].value_counts().plot(kind="bar");
df.info()
df.isna().sum()
df.describe()
pd.crosstab(df["Drug"], df["Sex"])

pd.crosstab(df["Drug"], df["Sex"]).plot(kind="bar", figsize=(10, 6))
plt.title("Drug vs Sex")
plt.xlabel("Drug Type")
plt.ylabel("Sex")
plt.xticks(rotation=0);
pd.crosstab(df["Drug"], df["BP"])

pd.crosstab(df["Drug"], df["BP"]).plot(kind="bar",
                                   figsize=(10, 6))

plt.title("Drug vs BP")
plt.xlabel("Drug Type")
plt.ylabel("BP")
plt.xticks(rotation=0);
pd.crosstab(df["Drug"], df["Cholesterol"])

pd.crosstab(df["Drug"], df["Cholesterol"]).plot(kind="bar",
                                   figsize=(10, 6))
plt.title("Drug vs Cholesterol")
plt.xlabel("Drug Type")
plt.ylabel("Cholesterol")
plt.xticks(rotation=0);

pd.crosstab(df["Sex"], df["Cholesterol"])
pd.crosstab(df["Sex"], df["BP"])
pd.crosstab(df["Cholesterol"], df["BP"])
corr_matrix = df.corr()
fig, ax = plt.subplots(figsize=(15, 10))
ax = sns.heatmap(corr_matrix, 
                 annot=True,
                 linewidths=0.5,
                 fmt=".2f",
                 cmap="YlGnBu");

np.random.seed(42)

X_train, X_test, y_train, y_test = train_test_split(df.drop("Drug", axis = 1),
                                                    df["Drug"],
                                                    test_size=0.1)
x = df.drop("Drug", axis = 1)
y = df["Drug"]

p_values = f_regression(x,y)[1]
len(p_values)
l = []

col = list(df.columns)
iter_df = 0

for value in p_values:
    if col[iter_df] == "close":
        iter_df += 1
        
    l.append({col[iter_df] : value.round(3)})
    iter_df += 1
    
l

# Put models in a dictionary
models = {"ANN": MLPClassifier(),
          "Random Forest": RandomForestClassifier(),
          "SVM": SVC(),
         "XGBoost": XGBClassifier()}

# Create a function to fit and score models
def fit_and_score(models, X_train, X_test, y_train, y_test):
    """
    Fits and evaluates given machine learning models.
    models : a dict of differetn Scikit-Learn machine learning models
    X_train : training data (no labels)
    X_test : testing data (no labels)
    y_train : training labels
    y_test : test labels
    """
    # Set random seed
    np.random.seed(42)
    # Make a dictionary to keep model scores
    model_scores = {}
    # Loop through models
    for name, model in models.items():
        # Fit the model to the data
        model.fit(X_train, y_train)
        # Evaluate the model and append its score to model_scores
        model_scores[name] = model.score(X_test, y_test)
    return model_scores
model_scores = fit_and_score(models=models,
                             X_train=X_train,
                             X_test=X_test,
                             y_train=y_train,
                             y_test=y_test)

model_scores

model_compare = pd.DataFrame(model_scores, index=["accuracy"])
model_compare.T.plot.bar();

rf_grid = {"n_estimators": np.arange(10, 1000, 50),
           "max_depth": [None, 3, 5, 10],
           "min_samples_split": np.arange(2, 20, 2),
           "min_samples_leaf": np.arange(1, 20, 2)}

# Setup random seed
np.random.seed(42)

# Setup random hyperparameter search for RandomForestClassifier
rs_rf = RandomizedSearchCV(RandomForestClassifier(), 
                           param_distributions=rf_grid,
                           cv=5,
                           n_iter=20,
                           verbose=True)

# Fit random hyperparameter search model for RandomForestClassifier()
rs_rf.fit(X_train, y_train)

rs_rf.best_params_
rs_rf.score(X_test, y_test)
y_preds = rs_rf.predict(X_test)
sns.set(font_scale=1.5)

def plot_conf_mat(y_test, y_preds):
    """
    Plots a nice looking confusion matrix using Seaborn's heatmap()
    """
    fig, ax = plt.subplots(figsize=(3, 3))
    ax = sns.heatmap(confusion_matrix(y_test, y_preds),
                     annot=True,
                     cbar=False)
    plt.xlabel("True label")
    plt.ylabel("Predicted label")
    
    bottom, top = ax.get_ylim()
    ax.set_ylim(bottom + 0.5, top - 0.5)

plot_conf_mat(y_test, y_preds)
print(classification_report(y_test, y_preds))
import pickle
from sklearn.ensemble import RandomForestClassifier